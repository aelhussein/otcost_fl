import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# import warnings # Replaced with logging
import os
from typing import Optional, List, Dict
import matplotlib.lines as mlines 
import logging # Added

logger = logging.getLogger(__name__) # Added

def pivot_results_comparison(results_df: pd.DataFrame) -> pd.DataFrame:
    """
    Pivots the results table to compare the primary metric across parameter sets.

    Args:
        results_df: The combined DataFrame returned by PipelineRunner.

    Returns:
        A pivoted DataFrame.
    """
    if results_df is None or results_df.empty:
        return pd.DataFrame()

    # Create a unified 'Primary_Metric' column based on OT_Method
    # This assumes you know the main metric for each method
    def get_primary_metric(row):
        if row['OT_Method'] == 'feature_error':
            return row['FeatureErrorOT_Cost'] # Lower is better
        elif row['OT_Method'] == 'decomposed':
            return row['Decomposed_CombinedScore'] # Lower is better
        elif row['OT_Method'] == 'fixed_anchor':
            return row['FixedAnchor_TotalCost']
        elif row['OT_Method'] == 'direct_ot':
            return row['DirectOT_Cost']  # New entry for direct_ot
        else:
            return np.nan

    temp_df = results_df.copy()
    temp_df['Primary_Metric'] = temp_df.apply(get_primary_metric, axis=1)

    # Define columns to keep alongside the pivoted values (optional)
    index_cols = ['Cost', 'Local_Final_Loss', 'FedAvg_Final_Loss', 'Loss_Delta']
    # Ensure index_cols are present
    index_cols = [col for col in index_cols if col in temp_df.columns]


    try:
        # Pivot table: Costs as rows, Parameter Sets as columns, Primary Metric as values
        pivot_df = pd.pivot_table(temp_df,
                                  index=index_cols,
                                  columns='Param_Set_Name',
                                  values='Primary_Metric')
        return pivot_df.reset_index() # Reset index to make index_cols regular columns
    except Exception as e:
        logger.error(f"Could not pivot table: {e}") # Changed from print to logger.error
        return pd.DataFrame()



def plot_ot_metrics_vs_perf_delta(
    results_df: pd.DataFrame,
    main_title: Optional[str] = None,
    save_path: Optional[str] = None
    ):
    """
    Generates a figure with one subplot per OT Method found in the DataFrame.
    Each subplot shows the primary metric for that method vs. Loss_Delta_pct,
    with its own legend for the Parameter Sets relevant to that method.

    Args:
        results_df: DataFrame generated by the pipeline (long format).
        main_title: Optional main title for the entire figure.
        save_path: Optional path to save the plot figure. If None, displays the plot.
    """
    # --- Input Validation & Setup ---
    if results_df is None or results_df.empty:
        logger.warning("Input DataFrame is empty or None. Cannot generate plot.") # Changed from warnings.warn
        return

    required_cols = ['Cost', 'OT_Method', 'Param_Set_Name',
                     'Local_Final_Loss', 'FedAvg_Final_Loss', 'Loss_Delta']
    if not all(col in results_df.columns for col in required_cols):
        missing = [col for col in required_cols if col not in results_df.columns]
        logger.warning(f"Input DataFrame missing required columns: {missing}. Cannot plot.") # Changed from warnings.warn
        return

    plot_df = results_df.copy()

    # --- Calculate Percentage Delta ---
    plot_df['Loss_Delta_pct'] = np.where(
        np.abs(plot_df['Local_Final_Loss']) > 1e-9,
        (plot_df['Loss_Delta'] / plot_df['Local_Final_Loss']) * 100.0,
        np.nan
    )
    y_var = 'Loss_Delta_pct'
    y_label = "Performance Delta (%) [(Local - FedAvg)/Local]"

    # --- Define Primary Metric per Method ---
    primary_metric_map = {
        'feature_error': 'FeatureErrorOT_Cost',
        'decomposed': 'Decomposed_CombinedScore',
        'fixed_anchor': 'FixedAnchor_TotalCost',
        'direct_ot': 'DirectOT_Cost'
    }
    metric_labels = {
        'feature_error': 'Feature-Error OT Cost',
        'decomposed': 'Decomposed Combined Score',
        'fixed_anchor': 'Fixed Anchor Total Cost',
        'direct_ot': 'Direct OT Cost'
    }
    # lower_is_better is not directly used for plotting structure now,
    # but kept for potential future use or interpretation.
    lower_is_better = {
        'feature_error': True, 'decomposed': True,
        'fixed_anchor': True, 'direct_ot': True
    }

    available_methods = sorted([m for m in plot_df['OT_Method'].unique() if m in primary_metric_map])

    if not available_methods:
        logger.warning("No defined OT methods found in the DataFrame. Cannot plot.") # Changed from warnings.warn
        return

    # --- Subplot Setup ---
    num_methods = len(available_methods)
    # Adjust figsize slightly if many methods, legends take space
    fig_width = max(7 * num_methods, 10) # Ensure minimum width
    fig, axes = plt.subplots(1, num_methods, figsize=(fig_width, 6), sharey=True, squeeze=False)
    axes = axes.flatten()

    plot_successful = False
    hue_var = 'Param_Set_Name'

    # --- Plotting Loop ---
    for i, method_type in enumerate(available_methods):
        ax = axes[i]
        metric_col = primary_metric_map[method_type]
        metric_label = metric_labels.get(method_type, method_type)

        if metric_col not in plot_df.columns:
            logger.warning(f"Primary metric column '{metric_col}' for method '{method_type}' not found. Skipping subplot.") # Changed from warnings.warn
            ax.set_title(f"{metric_label}\n(Data Unavailable)", fontsize=14)
            ax.text(0.5, 0.5, "Data Unavailable", ha='center', va='center', transform=ax.transAxes, fontsize=12, color='red')
            continue

        # Filter data *specific to this method*
        method_df = plot_df[plot_df['OT_Method'] == method_type].dropna(subset=[metric_col, y_var, hue_var]).copy()

        if method_df.empty:
            logger.warning(f"No valid data for subplot ('{metric_col}' vs '{y_var}' for method '{method_type}'). Skipping.") # Changed from warnings.warn
            ax.set_title(f"{metric_label}\n(No Valid Data)", fontsize=14)
            ax.text(0.5, 0.5, "No Valid Data", ha='center', va='center', transform=ax.transAxes, fontsize=12, color='orange')
            continue

        # Check unique parameter sets for this method
        param_sets_in_subplot = method_df[hue_var].unique()
        if len(param_sets_in_subplot) == 0:
             logger.warning(f"No unique '{hue_var}' values found for method '{method_type}' after filtering. Skipping plot elements.") # Changed from warnings.warn
             ax.set_title(f"{metric_label}\n(No Param Sets)", fontsize=14)
             ax.text(0.5, 0.5, "No Param Sets", ha='center', va='center', transform=ax.transAxes, fontsize=12, color='grey')
             continue


        try:
            method_df[metric_col] = pd.to_numeric(method_df[metric_col])
            method_df[y_var] = pd.to_numeric(method_df[y_var])
        except Exception as e:
             logger.warning(f"Numeric conversion error for subplot '{metric_label}': {e}. Skipping.") # Changed from warnings.warn
             ax.set_title(f"{metric_label}\n(Conversion Error)", fontsize=14)
             ax.text(0.5, 0.5, "Data Conversion Error", ha='center', va='center', transform=ax.transAxes, fontsize=12, color='purple')
             continue

        # --- Create the plot for this method ---
        try:
            sns.lineplot(
                data=method_df, x=metric_col, y=y_var, hue=hue_var, style=hue_var,
                marker='o', markersize=8, linewidth=2, ax=ax,
                legend='auto' # <<< Let seaborn handle legend creation per axis
            )
            # --- Adjust individual legend ---
            current_legend = ax.get_legend()
            if current_legend:
                current_legend.set_title('Parameter Set')
                plt.setp(current_legend.get_texts(), fontsize='small') # Adjust font size if needed
                plt.setp(current_legend.get_title(), fontsize='small')
            # else: # Should not happen with legend='auto' unless no data plotted
            #     logger.warning(f"Legend not automatically created for subplot {i} ({method_type})")

        except Exception as plot_err:
             logger.warning(f"Seaborn lineplot failed for subplot '{metric_label}': {plot_err}. Skipping plot elements.") # Changed from warnings.warn
             ax.set_title(f"{metric_label}\n(Plotting Error)", fontsize=14)
             ax.text(0.5, 0.5, "Plotting Error", ha='center', va='center', transform=ax.transAxes, fontsize=12, color='brown')
             continue

        ax.set_title(f"{metric_label} vs. Perf. Delta (%)", fontsize=14)
        ax.axhline(y=0, linestyle='--', color='black', linewidth=1)
        ax.set_xlabel(metric_label, fontsize=12)
        ax.grid(True, linestyle='--', alpha=0.6)

        plot_successful = True

    # --- Figure-Level Customization ---
    if not plot_successful:
         logger.warning("No subplots could be generated.") # Changed from warnings.warn
         plt.close(fig)
         return

    # Set shared Y-label using the first axis
    axes[0].set_ylabel(y_label, fontsize=12)

    fig_title = main_title if main_title else "OT Metrics vs. Performance Delta by Parameter Set"
    fig.suptitle(fig_title, fontsize=18, y=1.02) # Adjust title position

    # --- Remove Figure Legend Code ---
    # The block creating fig.legend() is removed.

    # Adjust layout to prevent overlap - may need tweaking
    fig.tight_layout()
    # plt.subplots_adjust(top=0.90) # Might be needed if suptitle overlaps axes titles

    # --- Output ---
    if save_path:
        try:
            save_dir = os.path.dirname(save_path)
            if save_dir and not os.path.exists(save_dir):
                os.makedirs(save_dir)
            # Save with bbox_inches='tight' to try and include legends if they extend slightly
            fig.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"Plot saved to: {save_path}") # Changed from print
        except Exception as e:
            logger.warning(f"Failed to save plot to {save_path}: {e}") # Changed from warnings.warn
        plt.close(fig)
    else:
        plt.show()